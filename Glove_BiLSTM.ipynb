{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC7MMItgzseA"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2wBhGzsz9Dl"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/ISR Dataset/IMDB Dataset.csv')\n",
        "\n",
        "data['review'] = data['review'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTTlI2Cd0HTX"
      },
      "source": [
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\",\n",
        "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
        "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
        "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
        "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
        "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\",\n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
        "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
        "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
        "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S-VEqc60Jwc"
      },
      "source": [
        "def remove_stopwords(data):\n",
        "  data['review without stopwords'] = data['review'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "  return data\n",
        "\n",
        "def remove_tags(string):\n",
        "    result = re.sub('<.*?>','',string)\n",
        "    return result\n",
        "\n",
        "data_without_stopwords = remove_stopwords(data)\n",
        "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
        "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sXhoU2L0TQ2"
      },
      "source": [
        "reviews_list = []\n",
        "for i in range(len(data['review'])):\n",
        "  reviews_list.append(data['review'][i])\n",
        "  sentiment = data_without_stopwords['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v1xi0KL1V8N"
      },
      "source": [
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiment)))\n",
        "\n",
        "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list, y, test_size=0.2, random_state = 45)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpTOS5zo1e3U"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "words_to_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCoYa50W1p9c"
      },
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "  return word_to_vec_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jm0G7Be1rTG"
      },
      "source": [
        "word_to_vec_map = read_glove_vector('/content/drive/MyDrive/ISR Dataset/glove.6B.50d.txt')\n",
        "\n",
        "maxLen = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsJsZO6D2xVd"
      },
      "source": [
        "vocab_len = len(words_to_index)\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index, :] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJIm5-AHDhLP"
      },
      "source": [
        "from keras.layers import Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V94V9w4PDf6B"
      },
      "source": [
        "#model=imdb_rating(input_shape)\n",
        "def imdb_rating(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X =Bidirectional(LSTM(128, return_sequences=True))(embeddings)\n",
        "\n",
        "  X = Dropout(0.3)(X)\n",
        "\n",
        "  X = Bidirectional(LSTM(128))(X)\n",
        "\n",
        "  X = Dropout(0.3)(X)\n",
        "\n",
        "  #X = LSTM(128)(X)\n",
        "  #X = Dense(64)\n",
        "  #X = Dropout(0.3)\n",
        "\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "jq4sdqIx2z0E",
        "outputId": "3b5ef5f3-0a93-48be-90da-293946c17853"
      },
      "source": [
        "#model=imdb_rating(input_shape)\n",
        "'''def imdb_rating(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\n",
        "\n",
        "  X = Dropout(0.6)(X)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "  X = Dropout(0.6)(X)\n",
        "\n",
        "  X = LSTM(128)(X)\n",
        "\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"def imdb_rating(input_shape):\\n\\n  X_indices = Input(input_shape)\\n\\n  embeddings = embedding_layer(X_indices)\\n\\n  X = LSTM(128, return_sequences=True)(embeddings)\\n\\n  X = Dropout(0.6)(X)\\n\\n  X = LSTM(128, return_sequences=True)(X)\\n\\n  X = Dropout(0.6)(X)\\n\\n  X = LSTM(128)(X)\\n\\n  X = Dense(1, activation='sigmoid')(X)\\n\\n  model = Model(inputs=X_indices, outputs=X)\\n\\n  return model\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIKJCvPgC6h-"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeB6unmRpa2a",
        "outputId": "8e91688a-188c-449a-e824-5cdc4a20d593"
      },
      "source": [
        "model = imdb_rating((maxLen,))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 150, 50)           5612100   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 150, 256)          183296    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 150, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 6,189,893\n",
            "Trainable params: 577,793\n",
            "Non-trainable params: 5,612,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56-WjIN-24l8"
      },
      "source": [
        "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZKW0U3l282z",
        "outputId": "7cd09402-ec3a-4fa5-b472-0bb0453a7427"
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 0.001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_indices, Y_train, batch_size=64, epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "625/625 [==============================] - 129s 161ms/step - loss: 0.6514 - accuracy: 0.6119\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 94s 150ms/step - loss: 0.6189 - accuracy: 0.6573\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 90s 145ms/step - loss: 0.4465 - accuracy: 0.7986\n",
            "Epoch 4/15\n",
            "625/625 [==============================] - 88s 141ms/step - loss: 0.4024 - accuracy: 0.8170\n",
            "Epoch 5/15\n",
            "625/625 [==============================] - 86s 138ms/step - loss: 0.3842 - accuracy: 0.8300\n",
            "Epoch 6/15\n",
            "625/625 [==============================] - 85s 136ms/step - loss: 0.3586 - accuracy: 0.8446\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.3331 - accuracy: 0.8567\n",
            "Epoch 8/15\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.3082 - accuracy: 0.8674\n",
            "Epoch 9/15\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.2983 - accuracy: 0.8702\n",
            "Epoch 10/15\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.2760 - accuracy: 0.8848\n",
            "Epoch 11/15\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.2539 - accuracy: 0.8940\n",
            "Epoch 12/15\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.2379 - accuracy: 0.9000\n",
            "Epoch 13/15\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.2151 - accuracy: 0.9117\n",
            "Epoch 14/15\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.1913 - accuracy: 0.9200\n",
            "Epoch 15/15\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.1827 - accuracy: 0.9253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7caa0286d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wVUT6ic1ZK06"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVY1gYalXkO7"
      },
      "source": [
        "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7BxgavZYMn"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Y5fW-xszbc",
        "outputId": "aa4040c3-1ad0-4051-866e-59c8b8707cae"
      },
      "source": [
        "model.evaluate(X_test_indices, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 22s 64ms/step - loss: 0.3622 - accuracy: 0.8655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3622434437274933, 0.8654999732971191]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13rDzbFQZqAY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SKL-SzCs9e4"
      },
      "source": [
        "preds = model.predict(X_test_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "w_vyAiZZ-7hy",
        "outputId": "d783e8d6-b774-461b-b8d4-d850451ce9b6"
      },
      "source": [
        "n = np.random.randint(0,9999)\n",
        "\n",
        "X_test[n]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a serial killer dies in a snowstorm and gets mutated into frosty the snowman\\'s evil twin. then goes on a killing spree. interesting plot. sounds scary. and it is scary. if you\\'re five years old. otherwise, it\\'s kind of cheesy. i saw it on cable and i\\'m glad i didn\\'t pay money to see it. it has all the charm and style of a low-budget movie which may become a cult film. i\\'m sure it has a loyal fan base somewhere. i\\'m just not in it. even though i didn\\'t like the movie as a whole, there were some scenes i found amusing. such as the bathtub scene and the post-explosion scene with the picasso reference. it was also enjoyable to watch the many ways the heroes try to kill jack and he just doesn\\'t seem to want to die. in short, \"jack frost\" is a good low-budget b-movie comedy, but a bad low-budget b-movie horror.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HBPpdoUHsUq",
        "outputId": "b205c5e2-df9f-4898-f0f8-e3b721373fd9"
      },
      "source": [
        "preds[n]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00520705], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTtNGnSj0xJ9",
        "outputId": "9592fef4-8836-4e58-8f8b-69b9206390a4"
      },
      "source": [
        "if preds[n] > 0.5:\n",
        "  print('predicted sentiment : positive')\n",
        "else:\n",
        "  print('precicted sentiment : negative')\n",
        "\n",
        "if (Y_test[n] == 1):\n",
        "  print('correct sentiment : positive')\n",
        "else:\n",
        "  print('correct sentiment : negative')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precicted sentiment : negative\n",
            "correct sentiment : negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMYh8m1_KQ45"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/ISR Dataset/imdb_weights_Glove_Bilstm.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBW2oE7OXaYJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWNz_CsuLg-q"
      },
      "source": [
        "reviews_list_idx = tokenizer.texts_to_sequences(reviews_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5VqbyPE2JXs"
      },
      "source": [
        "def add_score_predictions(data, reviews_list_idx):\n",
        "\n",
        "  data['sentiment score'] = 0\n",
        "\n",
        "  reviews_list_idx = pad_sequences(reviews_list_idx, maxlen=maxLen, padding='post')\n",
        "\n",
        "  review_preds = model.predict(reviews_list_idx)\n",
        "\n",
        "  data['sentiment score'] = review_preds\n",
        "\n",
        "  pred_sentiment = np.array(list(map(lambda x : 'positive' if x > 0.5 else 'negative',review_preds)))\n",
        "\n",
        "  data['predicted sentiment'] = 0\n",
        "\n",
        "  data['predicted sentiment'] = pred_sentiment\n",
        "\n",
        "  return data\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXFfXQs5LorY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2SPaF7N3C3g"
      },
      "source": [
        "data = add_score_predictions(data, reviews_list_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "e5h-s63wZXAZ",
        "outputId": "7c4930a2-5832-412f-89b1-273c382df893"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review without stopwords</th>\n",
              "      <th>clean_review</th>\n",
              "      <th>sentiment score</th>\n",
              "      <th>predicted sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
              "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
              "      <td>0.694208</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonderful little production. &lt;br /&gt;&lt;br /&gt;the f...</td>\n",
              "      <td>wonderful little production  the filming techn...</td>\n",
              "      <td>0.999623</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>0.996641</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically family little boy (jake) thinks zomb...</td>\n",
              "      <td>basically family little boy  jake  thinks zomb...</td>\n",
              "      <td>0.004695</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
              "      <td>petter mattei s  love time money  visually stu...</td>\n",
              "      <td>0.996964</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>i thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "      <td>thought movie right good job. wasn't creative ...</td>\n",
              "      <td>thought movie right good job  wasn t creative ...</td>\n",
              "      <td>0.999873</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>bad plot  bad dialogue  bad acting  idiotic di...</td>\n",
              "      <td>0.000788</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>i am a catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "      <td>catholic taught parochial elementary schools n...</td>\n",
              "      <td>catholic taught parochial elementary schools n...</td>\n",
              "      <td>0.055050</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>i'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "      <td>going disagree previous comment side maltin on...</td>\n",
              "      <td>going disagree previous comment side maltin on...</td>\n",
              "      <td>0.160507</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>no one expects the star trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "      <td>no one expects star trek movies high art, fans...</td>\n",
              "      <td>no one expects star trek movies high art  fans...</td>\n",
              "      <td>0.019200</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  ... predicted sentiment\n",
              "0      one of the other reviewers has mentioned that ...  ...            positive\n",
              "1      a wonderful little production. <br /><br />the...  ...            positive\n",
              "2      i thought this was a wonderful way to spend ti...  ...            positive\n",
              "3      basically there's a family where a little boy ...  ...            negative\n",
              "4      petter mattei's \"love in the time of money\" is...  ...            positive\n",
              "...                                                  ...  ...                 ...\n",
              "49995  i thought this movie did a down right good job...  ...            positive\n",
              "49996  bad plot, bad dialogue, bad acting, idiotic di...  ...            negative\n",
              "49997  i am a catholic taught in parochial elementary...  ...            negative\n",
              "49998  i'm going to have to disagree with the previou...  ...            negative\n",
              "49999  no one expects the star trek movies to be high...  ...            negative\n",
              "\n",
              "[50000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}